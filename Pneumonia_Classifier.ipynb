{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Pneumonia Image Classifier\n",
    "## In this notebook we're going to train a Neural Network to detect pneumonia in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get started by importing our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create a reference to our data directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = './input/train'\n",
    "test_data_dir = './input/test'\n",
    "val_data_dir = './input/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some variables that we're going to use in training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 5217\n",
    "nb_validation_samples = 17\n",
    "epochs = 20\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape our input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "input_shape = (img_width, img_height, 3)\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the size of our dataset, we'll need to use generators in order to feed the data to our model bit-by-bit\n",
    "### Let's create our generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_gen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_gen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_gen.flow_from_directory(\n",
    "    val_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's initialize our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(48, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit it using our training generator... it's going to take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "326/326 [==============================] - 187s 574ms/step - loss: 0.4679 - acc: 0.7847 - val_loss: 0.8095 - val_acc: 0.7500\n",
      "Epoch 2/20\n",
      "326/326 [==============================] - 182s 559ms/step - loss: 0.3106 - acc: 0.8719 - val_loss: 0.5392 - val_acc: 0.8750\n",
      "Epoch 3/20\n",
      "326/326 [==============================] - 200s 614ms/step - loss: 0.2719 - acc: 0.9022 - val_loss: 0.6166 - val_acc: 0.8125\n",
      "Epoch 4/20\n",
      "326/326 [==============================] - 201s 618ms/step - loss: 0.2355 - acc: 0.9122 - val_loss: 0.8213 - val_acc: 0.7500\n",
      "Epoch 5/20\n",
      "326/326 [==============================] - 202s 621ms/step - loss: 0.2337 - acc: 0.9174 - val_loss: 0.6801 - val_acc: 0.7500\n",
      "Epoch 6/20\n",
      "326/326 [==============================] - 194s 594ms/step - loss: 0.2257 - acc: 0.9231 - val_loss: 2.3351 - val_acc: 0.6250\n",
      "Epoch 7/20\n",
      "326/326 [==============================] - 199s 612ms/step - loss: 0.2233 - acc: 0.9268 - val_loss: 0.8405 - val_acc: 0.7500\n",
      "Epoch 8/20\n",
      "326/326 [==============================] - 199s 612ms/step - loss: 0.2026 - acc: 0.9306 - val_loss: 0.7109 - val_acc: 0.8125\n",
      "Epoch 9/20\n",
      "326/326 [==============================] - 191s 585ms/step - loss: 0.2142 - acc: 0.9289 - val_loss: 0.6529 - val_acc: 0.6875\n",
      "Epoch 10/20\n",
      "326/326 [==============================] - 205s 630ms/step - loss: 0.2021 - acc: 0.9327 - val_loss: 1.7669 - val_acc: 0.6250\n",
      "Epoch 11/20\n",
      "326/326 [==============================] - 219s 671ms/step - loss: 0.1881 - acc: 0.9375 - val_loss: 0.7763 - val_acc: 0.6250\n",
      "Epoch 12/20\n",
      "326/326 [==============================] - 204s 625ms/step - loss: 0.1955 - acc: 0.9390 - val_loss: 0.6367 - val_acc: 0.8125\n",
      "Epoch 13/20\n",
      "326/326 [==============================] - 211s 646ms/step - loss: 0.1852 - acc: 0.9365 - val_loss: 2.0899 - val_acc: 0.6250\n",
      "Epoch 14/20\n",
      "326/326 [==============================] - 208s 638ms/step - loss: 0.1966 - acc: 0.9367 - val_loss: 0.4640 - val_acc: 0.8125\n",
      "Epoch 15/20\n",
      "326/326 [==============================] - 197s 605ms/step - loss: 0.1948 - acc: 0.9356 - val_loss: 0.4405 - val_acc: 0.8750\n",
      "Epoch 16/20\n",
      "326/326 [==============================] - 194s 594ms/step - loss: 0.2039 - acc: 0.9375 - val_loss: 1.3912 - val_acc: 0.6875\n",
      "Epoch 17/20\n",
      "326/326 [==============================] - 194s 594ms/step - loss: 0.2101 - acc: 0.9335 - val_loss: 0.6160 - val_acc: 0.7500\n",
      "Epoch 18/20\n",
      "326/326 [==============================] - 199s 610ms/step - loss: 0.1959 - acc: 0.9373 - val_loss: 1.0942 - val_acc: 0.6875\n",
      "Epoch 19/20\n",
      "326/326 [==============================] - 199s 610ms/step - loss: 0.1934 - acc: 0.9373 - val_loss: 2.2831 - val_acc: 0.6875\n",
      "Epoch 20/20\n",
      "326/326 [==============================] - 180s 551ms/step - loss: 0.2136 - acc: 0.9371 - val_loss: 0.7208 - val_acc: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb1e6bdba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's evaluate it using our test generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327/327 [==============================] - 81s 248ms/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(test_generator, math.ceil(5217 / batch_size), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.47056583494376264, 0.9030963302752294]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
